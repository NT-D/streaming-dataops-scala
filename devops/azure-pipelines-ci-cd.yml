# TODO: Separate CI/CD pipeline if needed
# TODO: use variable for file name and path

trigger:
  branches:
    include:
    - master

pool:
  vmImage: 'ubuntu-latest'

steps:
  - task: UsePythonVersion@0
    inputs:
      versionSpec: '3.6'
      addToPath: true
      architecture: 'x64'

  - script: pip install --upgrade pip && pip install databricks-cli
    displayName: 'Install Databricks CLI'

  # TODO: Install specific version Java explicitly
  # Azure Pipeline uses AdoptOpenJDK 1.8.0_265 as default and this is expected one, so I skip to install JDK
  - script: java -version
    displayName: 'Show java version'

  # TODO: Install specific version sbt explicitly
  # Azure Pipeline automatically install sbt when script uses sbt comment, so I skip to install sbt
  - script: sbt compile
    displayName: 'Compile scala code'

  # TODO: Publish test results
  # TODO: Calculate test coverage and publish it
  - script: sbt test
    displayName: 'Test scala code'

  - script: sbt publishLocal
    displayName: 'Build package (jar file)'

  - task: AzureKeyVault@1
    inputs:
      azureSubscription: $(azure-subscription)
      KeyVaultName: $(key-vault-name)
      SecretsFilter: '*'
      RunAsPreJob: false

  - script: databricks clusters start --cluster-id $(databricks-cluster-scala-id)
    displayName: 'Start a target cluster'
    env:
      DATABRICKS_HOST: $(databricks-host)
      DATABRICKS_TOKEN: $(databricks-token)

  - script: |
      dbfs mkdirs dbfs:/FileStore/jars
      dbfs rm dbfs:/FileStore/jars/streaming-dataops-scala_2.11-0.1.jar
      dbfs cp "./target/scala-2.11/streaming-dataops-scala_2.11-0.1.jar" dbfs:/FileStore/whls
    displayName: 'Upload jar file to DBFS(Databricks File System)'
    env:
      DATABRICKS_HOST: $(databricks-host)
      DATABRICKS_TOKEN: $(databricks-token)

  - script: |
      databricks libraries install --cluster-id $(databricks-cluster-scala-id) --whl dbfs:/FileStore/whls/pyot-0.0.1-py3-none-any.whl
      databricks libraries install --cluster-id $(databricks-cluster-scala-id) --maven-coordinates com.microsoft.azure:azure-eventhubs-spark_2.11:2.3.16
    displayName: 'Install package to a target cluster'
    env:
      DATABRICKS_HOST: $(databricks-host)
      DATABRICKS_TOKEN: $(databricks-token)